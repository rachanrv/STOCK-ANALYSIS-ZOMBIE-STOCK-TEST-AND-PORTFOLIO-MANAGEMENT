{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nOwlAhrboWEb"
   },
   "source": [
    "# ***PART-I***\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j88EySx80lwf"
   },
   "source": [
    "# MOUNTING GOOGLE DRIVE "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Ki3OwhI3YWSL"
   },
   "source": [
    "**THE GOOGLE DRIVE IS MOUNTED TO ACCESS THE FILES IN GOOGLE CLOUD**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ymoQ6TMJv7pK"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZZY2NrFQwHrS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.core.common.is_list_like = pd.api.types.is_list_like\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas_datareader as pdr\n",
    "import datetime \n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import seaborn as sns\n",
    "import os\n",
    "import shutil\n",
    "% matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xARKGple0b2k"
   },
   "source": [
    "# CREATING MAIN DIRECTORY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mIrOM9U2ZBGi"
   },
   "source": [
    "**CREATING DIRECTORIES TO SAVE THE RESULTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "E6eRJrEJwKdu"
   },
   "outputs": [],
   "source": [
    "path='/content/drive/Shared drives/OPIM5512 - Data Sci. w Python/Data/Final Results'\n",
    "try:\n",
    "  os.mkdir(path)\n",
    "except OSError:\n",
    "  print (\"Creation of the directory %s failed\" % path)\n",
    "else:\n",
    "  print (\"Successfully created the directory %s \" % path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VbadeF0R1xnH"
   },
   "source": [
    "# WEB SCRAPING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xuHb0saRZYfG"
   },
   "source": [
    "**EXTRACTING TICKER SYMBOLS FROM 5 ETF INDICES FOR COVID TOP 3 WINNING AND LOSING SECTORS** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ldABXc_71usX"
   },
   "outputs": [],
   "source": [
    "%pip install fix_yahoo_finance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "prVA_3Zr1wvx"
   },
   "outputs": [],
   "source": [
    "import fix_yahoo_finance as fyf\n",
    "from pandas_datareader import data as pdr\n",
    "fyf.pdr_override()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VR1exdKXAKsb"
   },
   "source": [
    "# FILTERING STOCK TICKERS FROM ETF INDICES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3HRtnP2bb8yp"
   },
   "source": [
    "**EXTRACTED THE TABLES OF TICKERS FROM ETF INDICES,ONLY FILTERED THE DUPLICATES IN THE SECTOR AND SELECTED THE TOP 3** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "__vmJZcg2BYN"
   },
   "outputs": [],
   "source": [
    "T=['VGT','XLK','IYW','SKYY','FTEC']\n",
    "CD=['XLY','VCR','FXD','IBUY','XRT']\n",
    "HC=['XLV','VHT','IBB','IHI','FBT']\n",
    "F=['VFH','FNCL','XLF','IYF','FAS']\n",
    "U=['FUTY','XLU','VPU','IDU','FXU']\n",
    "CS=['XLP','VDC','FSTA','KXI','RHS']\n",
    "web='https://screener.fidelity.com/ftgw/etf/goto/snapshot/snapshot.jhtml?symbols='\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xrUa4QXo2GZN"
   },
   "outputs": [],
   "source": [
    "table=pd.DataFrame()\n",
    "for x in T:\n",
    "  ETFpayload = pd.read_html(web+x)\n",
    "  table=pd.concat([table,ETFpayload[17].loc[0:2,0]],axis=0)\n",
    "t=table[table.duplicated(keep=False)]\n",
    "t=t.drop_duplicates()\n",
    "if len(t)>3:\n",
    "  t=t.iloc[0:3]\n",
    "for x in range(3):\n",
    "  t.iloc[x,0]=''.join(filter(str.isalpha,t.iloc[x,0]))\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DWi3RQ923wC4"
   },
   "outputs": [],
   "source": [
    "table=pd.DataFrame()\n",
    "for x in CD:\n",
    "  ETFpayload = pd.read_html(web+x)\n",
    "  table=pd.concat([table,ETFpayload[17].loc[0:2,0]],axis=0)\n",
    "cd=table[table.duplicated(keep=False)]\n",
    "cd=cd.drop_duplicates()\n",
    "if len(cd)>3:\n",
    "  cd=cd.iloc[0:3]\n",
    "for x in range(3):\n",
    "  cd.iloc[x,0]=''.join(filter(str.isalpha,cd.iloc[x,0]))\n",
    "cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0_nCoIBq3x-1"
   },
   "outputs": [],
   "source": [
    "table=pd.DataFrame()\n",
    "for x in HC:  \n",
    "  ETFpayload = pd.read_html(web+x)\n",
    "  table=pd.concat([table,ETFpayload[17].loc[0:2,0]],axis=0)\n",
    "hc=table[table.duplicated(keep=False)]\n",
    "hc=hc.drop_duplicates()\n",
    "if len(hc)>3:\n",
    "  hc=hc.iloc[0:3]\n",
    "for x in range(3):\n",
    "  hc.iloc[x,0]=''.join(filter(str.isalpha,hc.iloc[x,0]))\n",
    "hc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5jMh8Qf_30mR"
   },
   "outputs": [],
   "source": [
    "table=pd.DataFrame()\n",
    "for x in F:\n",
    "  ETFpayload = pd.read_html(web+x)\n",
    "  if x=='FAS':\n",
    "    table=pd.concat([table,ETFpayload[16].loc[0:2,0]],axis=0)\n",
    "  else:\n",
    "    table=pd.concat([table,ETFpayload[17].loc[0:2,0]],axis=0)\n",
    "f=table[table.duplicated(keep=False)]\n",
    "for x in range(len(f)):\n",
    "  if f.iloc[x,0]=='BRK/B':\n",
    "    f.iloc[x,0]=f.iloc[-1,0]\n",
    "f=f.drop_duplicates()\n",
    "if len(f)>3:\n",
    "  f=f.iloc[0:3]\n",
    "for x in range(3):\n",
    "  f.iloc[x,0]=''.join(filter(str.isalpha,f.iloc[x,0]))\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2dGFuQM131Nu"
   },
   "outputs": [],
   "source": [
    "table=pd.DataFrame()\n",
    "for x in U:\n",
    "  ETFpayload = pd.read_html(web+x)\n",
    "  table=pd.concat([table,ETFpayload[17].loc[0:2,0]],axis=0)\n",
    "u=table[table.duplicated(keep=False)]\n",
    "u=u.drop_duplicates()\n",
    "if len(u)>3:\n",
    "  u=u.iloc[0:3]\n",
    "for x in range(3):\n",
    "  u.iloc[x,0]=''.join(filter(str.isalpha,u.iloc[x,0]))\n",
    "u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sfTd8rc4319R"
   },
   "outputs": [],
   "source": [
    "table=pd.DataFrame()\n",
    "for x in CS:\n",
    "  ETFpayload = pd.read_html(web+x)\n",
    "  table=pd.concat([table,ETFpayload[17].loc[0:2,0]],axis=0)\n",
    "cs=table[table.duplicated(keep=False)]\n",
    "cs=cs.drop_duplicates()\n",
    "if len(cs)>3:\n",
    "  cs=cs.iloc[0:3]\n",
    "for x in range(3):\n",
    "  cs.iloc[x,0]=''.join(filter(str.isalpha,cs.iloc[x,0]))\n",
    "cs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Kydi4Fs9mUNL"
   },
   "source": [
    "# SETTING DATA DIRECTORIES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qHHzChPberRI"
   },
   "source": [
    "**DIRECTORIES FOR ALL SECTORS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-MrvfDjiDmud"
   },
   "outputs": [],
   "source": [
    "def directory(df):\n",
    "  if str(df)==str(t):\n",
    "    dir='/content/drive/Shared drives/OPIM5512 - Data Sci. w Python/Data/Final Results/Technology/'\n",
    "  elif str(df)==str(cd):\n",
    "    dir='/content/drive/Shared drives/OPIM5512 - Data Sci. w Python/Data/Final Results/Consumer Discretionary/'\n",
    "  elif str(df)==str(hc):\n",
    "    dir='/content/drive/Shared drives/OPIM5512 - Data Sci. w Python/Data/Final Results/Healthcare/'\n",
    "  elif str(df)==str(f):\n",
    "    dir='/content/drive/Shared drives/OPIM5512 - Data Sci. w Python/Data/Final Results/Financials/'\n",
    "  elif str(df)==str(u):\n",
    "    dir='/content/drive/Shared drives/OPIM5512 - Data Sci. w Python/Data/Final Results/Utilities/'\n",
    "  else:\n",
    "    dir='/content/drive/Shared drives/OPIM5512 - Data Sci. w Python/Data/Final Results/Consumer Staples/'\n",
    "  return dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y-cxfxJImOkc"
   },
   "source": [
    "# DATA EXTRACTION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ntGGgP_Ie5wC"
   },
   "source": [
    "**DATA WAS EXTRACTED FROM YAHOO FINANCE DATABASE USING TICKERS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rlfe5_smFLKS"
   },
   "outputs": [],
   "source": [
    "def dataextract(df):\n",
    "  one=str(df.iloc[0,0])\n",
    "  two=str(df.iloc[1,0])\n",
    "  three=str(df.iloc[2,0])\n",
    "  data1 = pdr.get_data_yahoo(one,start='2017-01-01')\n",
    "  data2 = pdr.get_data_yahoo(two,start='2017-01-01')\n",
    "  data3 = pdr.get_data_yahoo(three,start='2017-01-01')\n",
    "  return data1,data2,data3,one,two,three"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9GB_2d6cHRaJ"
   },
   "source": [
    "# DATA IMPUTATION\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8wK57F_dgOWY"
   },
   "source": [
    "**DATA WAS IMPUTED FOR CONSISTENT STOCK DATA DAILY USING FORWARD FILL AND BACKWARD FILL**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "i0FXuS8fHQRC"
   },
   "outputs": [],
   "source": [
    "def dataimpute(data):\n",
    "  dt = datetime.date(2017, 1, 1)\n",
    "  end = datetime.date.today()-datetime.timedelta(days=2)\n",
    "  day=pd.date_range(start=dt,end=end,freq='D')\n",
    "  temp=pd.DataFrame(data=day,columns=['Date'])\n",
    "  temp\n",
    "  date=data.index\n",
    "  for i in date:\n",
    "      for x in range(len(temp)):\n",
    "        if i==temp.loc[x,'Date']:\n",
    "          temp.loc[x,'High']=data.loc[i,'High']\n",
    "          temp.loc[x,'Low']=data.loc[i,'Low']\n",
    "          temp.loc[x,'Open']=data.loc[i,'Open']\n",
    "          temp.loc[x,'Close']=data.loc[i,'Close']\n",
    "          temp.loc[x,'Adj Close']=data.loc[i,'Adj Close']\n",
    "          temp.loc[x,'Volume']=data.loc[i,'Volume']\n",
    "  #Imputation\n",
    "  #temp=temp.interpolate(method=\"linear\") #Another Method\n",
    "  temp=temp.ffill()\n",
    "  temp=temp.bfill()\n",
    "  temp=temp.set_index('Date')  \n",
    "  return temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OGiHoUbyDrTq"
   },
   "source": [
    "# DATA VISUALISATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HttrQ9qxhR-S"
   },
   "source": [
    "**DATA WAS PLOTTED AS LINE PLOTS,BOXPLOTS AND DENSITY PLOTS WITH HISTOGRAMS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xEu1_hgCmYgr"
   },
   "outputs": [],
   "source": [
    "#for setting figure size\n",
    "from matplotlib.pylab import rcParams\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "djmj8JdfIjYe"
   },
   "outputs": [],
   "source": [
    "def graph(data,dir1,number,time):\n",
    "   rcParams['figure.figsize'] = 20,10\n",
    "   params = {'legend.fontsize': 'x-large',\n",
    "            'axes.labelsize': 'x-large',\n",
    "          'axes.titlesize':'x-large',\n",
    "          'xtick.labelsize':'x-large',\n",
    "          'ytick.labelsize':'x-large'}\n",
    "   rcParams.update(params)\n",
    "\n",
    "   figure, axes = plt.subplots(nrows=4, ncols=2,sharex=True)\n",
    "   figure.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    "   x=list(data.index.values)\n",
    " \n",
    "   axes[0,0].plot(x, data['Volume'], color='blue') \n",
    "   axes[0,0].set_title('VOLUME VERSUS DATE')\n",
    "   #axes[0,0].set(xlabel='DATES',ylabel='VOLUME')\n",
    "   \n",
    "\n",
    "   axes[0,1].plot(x, data['High'], color='g')\n",
    "   axes[0,1].plot(x, data['Low'], color='r')\n",
    "   axes[0,1].plot(x, data['Open'], color='m')\n",
    "   axes[0,1].plot(x, data['Close'], color='c')\n",
    "   axes[0,1].plot(x, data['Adj Close'], color='y')\n",
    "   axes[0,1].set_title('PRICES VERSUS DATE')\n",
    "   #axes[0,1].set(xlabel='DATES',ylabel='PRICES')\n",
    "\n",
    "   axes[1,0].plot(x, data['High'], color='g')\n",
    "   axes[1,0].set_title('HIGH PRICES VERSUS DATE')\n",
    "   #axes[1,0].set(xlabel='DATES',ylabel='HIGH PRICES')\n",
    "\n",
    "   axes[1,1].plot(x, data['Low'], color='r')\n",
    "   axes[1,1].set_title('LOW PRICES VERSUS DATE')\n",
    "   #axes[1,1].set(xlabel='DATES',ylabel='LOW PRICES')\n",
    "\n",
    "   axes[2,0].plot(x, data['Open'], color='m')\n",
    "   axes[2,0].set_title('OPEN PRICES VERSUS DATE')\n",
    "   #axes[2,0].set(xlabel='DATES',ylabel='OPEN PRICES')\n",
    "\n",
    "   axes[2,1].plot(x, data['Close'], color='c')\n",
    "   axes[2,1].set_title('CLOSE PRICES VERSUS DATE')\n",
    "   #axes[2,1].set(xlabel='DATES',ylabel='CLOSE PRICES')\n",
    "\n",
    "   axes[3,0].plot(x, data['Adj Close'], color='y',)\n",
    "   #axes[3,0].set_xticklabels([])\n",
    "   axes[3,0].set_title('ADJUSTED CLOSE PRICES VERSUS DATE')\n",
    "   #axes[3,0].set(xlabel='DATES',ylabel='ADJUSTED CLOSE PRICES')\n",
    "  \n",
    "   axes[3,1].plot(x, data['Open'], color='m') \n",
    "   axes[3,1].plot(x, data['Close'], color='c')\n",
    "   axes[3,1].plot(x, data['Adj Close'], color='y')\n",
    "   #axes[3,1].set_xticklabels([])\n",
    "   axes[3,1].set_title('OPEN,CLOSE AND PRICES VERSUS DATE')\n",
    "   #axes[3,1].set(xlabel='DATES',ylabel='PRICES')\n",
    "\n",
    "   figure.savefig(dir1+'/'+time+'/VOLUME AND PRICES GRAPH '+number+' '+time+'.png')\n",
    "   plt.clf()\n",
    "   \n",
    "   figure, axes = plt.subplots(nrows=3, ncols=2,sharex=True)\n",
    "   figure.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    " \n",
    "   sns.distplot(data['Volume'],ax=axes[0,0])\n",
    "   axes[0,0].set_title('VOLUME')\n",
    "  \n",
    "   sns.distplot(data['High'],ax=axes[0,1])\n",
    "   axes[0,1].set_title('HIGH PRICE')\n",
    "\n",
    "   sns.distplot(data['Low'],ax=axes[1,0])\n",
    "   axes[1,0].set_title('LOW PRICES')\n",
    "  \n",
    "   sns.distplot(data['Open'],ax=axes[1,1])\n",
    "   axes[1,1].set_title('OPEN PRICES')\n",
    "\n",
    "   sns.distplot(data['Close'],ax=axes[2,0])\n",
    "   axes[2,0].set_title('CLOSE PRICES')\n",
    "\n",
    "   sns.distplot(data['Adj Close'],ax=axes[2,1])\n",
    "   axes[2,1].set_title('ADJUSTED CLOSE PRICES')  \n",
    "  \n",
    "   figure.savefig(dir1+'/'+time+'/DENSITY PLOTS '+number+' '+time+'.png')\n",
    "   plt.clf()\n",
    "\n",
    "   figure, axes = plt.subplots(nrows=3, ncols=2,sharex=True)\n",
    "   figure.subplots_adjust(hspace=0.4, wspace=0.4)\n",
    " \n",
    "   sns.boxplot(data['Volume'],ax=axes[0,0])\n",
    "   axes[0,0].set_title('VOLUME')\n",
    "  \n",
    "   sns.boxplot(data['High'],ax=axes[0,1])\n",
    "   axes[0,1].set_title('HIGH PRICE')\n",
    "\n",
    "   sns.boxplot(data['Low'],ax=axes[1,0])\n",
    "   axes[1,0].set_title('LOW PRICES')\n",
    "  \n",
    "   sns.boxplot(data['Open'],ax=axes[1,1])\n",
    "   axes[1,1].set_title('OPEN PRICES')\n",
    "\n",
    "   sns.boxplot(data['Close'],ax=axes[2,0])\n",
    "   axes[2,0].set_title('CLOSE PRICES')\n",
    "\n",
    "   sns.boxplot(data['Adj Close'],ax=axes[2,1])\n",
    "   axes[2,1].set_title('ADJUSTED CLOSE PRICES')  \n",
    "  \n",
    "   figure.savefig(dir1+'/'+time+'/BOX PLOTS '+number+' '+time+ \".png\")\n",
    "   plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bX05CQZ7pQ9r"
   },
   "outputs": [],
   "source": [
    "pip install https://github.com/pandas-profiling/pandas-profiling/archive/master.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IbOejseOqbWX"
   },
   "outputs": [],
   "source": [
    "from pandas_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CmvAmN9BCYjM"
   },
   "source": [
    "# CORRELATION MATRIX AND PAIR PLOTS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2yA7iDSPifHw"
   },
   "source": [
    "**PAIRPLOTS AND CORRELATION MATRIX  WERE PLOTTED.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4EHp6EiPjGTX"
   },
   "source": [
    "**A DETAILED REPORT WAS MADE USING  GUI ON THE FEATURE SELECTION PROCESS.**\n",
    "\n",
    "\n",
    ">  **ONLY VOLUME CAN BE USED AS THERE IS SOME CORRELATION BETWEEN OUR TARGET,ADJUSTED CLOSE PRICE.**\n",
    "\n",
    "\n",
    ">**REST OF THE VARIABLES COULD DERIVE OUR TARGET EASILY.**\n",
    "\n",
    "\n",
    "> **NO MISSING VALUES IN THE DATASET**\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SLMJjvQvusNH"
   },
   "outputs": [],
   "source": [
    "def datainspect(data,dir1,number,time):\n",
    "  pp=sns.pairplot(data,height=2)\n",
    "  pp.savefig(dir1 + \"/\"+time+ \"/Pairplot new \"+ number +\" \"+ time +  \".png\")\n",
    "  plt.clf()\n",
    "  correlation_matrix = data.corr()\n",
    "  sns.set(rc={'figure.figsize':(10,10)})\n",
    "  sns_plot1=sns.heatmap(data=correlation_matrix, annot=True)\n",
    "  fig = sns_plot1.get_figure()\n",
    "  fig.savefig(dir1+\"/\"+time+\"/Correlation matrix new \"+number+\" \"+time+\".png\")\n",
    "  plt.clf()\n",
    "  profile=ProfileReport(data)\n",
    "  profile.to_file(dir1+\"/\"+time+\"/Report new \"+number+\" \"+time+\".html\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1N7u1EJe7ZS3"
   },
   "source": [
    "# DATA PREPROCESSING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "PacBQA8klGk4"
   },
   "source": [
    "**NORMALISATION WAS USED TO THE DATASET BECAUSE WE DIDN'T HAVE ANY OUTLIER IN THE DATASETS**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3mwSktuS2YNa"
   },
   "outputs": [],
   "source": [
    "def datapreprocess(data):\n",
    "  scaler = MinMaxScaler(feature_range=(0, 1)) \n",
    "  scaled_values = scaler.fit_transform(data) \n",
    "  data.loc[:,:] = scaled_values\n",
    "  return data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "sAv7MwlhmZrc"
   },
   "source": [
    "# DATA WRANGLING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vEPYrog_mjbA"
   },
   "source": [
    "**ALL THE ABOVE FUNCTIONS WERE RUN ON 18 DATASETS USING THIS FUNCTION**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8ypy7zrMUnCi"
   },
   "outputs": [],
   "source": [
    "def datawrangling(d):\n",
    "  dir=directory(d)\n",
    "  data1,data2,data3,one,two,three=dataextract(d)\n",
    "  # define the name of the directory to be created\n",
    "  comp=[one,two,three]\n",
    "  for j in comp:\n",
    "    p=dir\n",
    "    q=j+\"/\"+\"before\"\n",
    "    path=p+q\n",
    "    try:\n",
    "      os.makedirs(path)\n",
    "    except OSError:\n",
    "      print (\"Creation of the directory %s failed\" % path)\n",
    "    else:\n",
    "      print (\"Successfully created the directory %s\" % path)\n",
    "    q=j+\"/\"+\"after\"\n",
    "    path=p+q\n",
    "    try:\n",
    "      os.makedirs(path)\n",
    "    except OSError:\n",
    "      print (\"Creation of the directory %s failed\" % path)\n",
    "    else:\n",
    "      print (\"Successfully created the directory %s\" % path)\n",
    "  data1=dataimpute(data1)\n",
    "  data2=dataimpute(data2)\n",
    "  data3=dataimpute(data3)\n",
    "  dir1=os.path.join(dir, one)\n",
    "  dir2=os.path.join(dir, two)\n",
    "  dir3=os.path.join(dir, three)\n",
    "  time='before'\n",
    "  graph(data1,dir1,one,time)\n",
    "  graph(data2,dir2,two,time)\n",
    "  graph(data3,dir3,three,time)\n",
    "  datainspect(data1,dir1,one,time)\n",
    "  datainspect(data2,dir2,two,time)\n",
    "  datainspect(data3,dir3,three,time)\n",
    "  #datapreprocessing\n",
    "  scaled_data1=datapreprocess(data1)\n",
    "  scaled_data2=datapreprocess(data2)\n",
    "  scaled_data3=datapreprocess(data3)\n",
    "  time='after'\n",
    "  graph(scaled_data1,dir2,two,time)\n",
    "  graph(scaled_data1,dir3,three,time)\n",
    "  datainspect(scaled_data1,dir1,one,time)\n",
    "  datainspect(scaled_data2,dir2,two,time)\n",
    "  datainspect(scaled_data3,dir3,three,time)\n",
    "  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WGVzwvn-EQVh"
   },
   "outputs": [],
   "source": [
    "#datawrangling(t)\n",
    "#datawrangling(cd)\n",
    "#datawrangling(hc)\n",
    "#datawrangling(f)\n",
    "#datawrangling(u)\n",
    "#datawrangling(cs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4VB2pwB9RtA4"
   },
   "source": [
    "# ***PART-II***\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y7hnB98RASL6"
   },
   "source": [
    "# MODELING FUNCTIONS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UwngmtCsnYNo"
   },
   "source": [
    "**FUNCTIONS WERE MADE FOR EACH MODEL TO GENERATE GRAPHS AND TRAIN,FIT AND TEST MODELS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XsPYXS_x-NDI"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FXsTCPJpk_FX"
   },
   "source": [
    "# DATASET PARTITION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jxPsUZonn1bO"
   },
   "source": [
    "**DATA WAS PARTITIONED INTO TRAINING,VALIDATION AND TESTING SETS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-NfDlNxGo7Mr"
   },
   "outputs": [],
   "source": [
    "def datapartition(d):\n",
    "  dir=directory(d)\n",
    "  data1,data2,data3,one,two,three=dataextract(d)\n",
    "  # define the name of the directory to be created\n",
    "  comp=[one,two,three]\n",
    "  for j in comp:\n",
    "    p=dir\n",
    "    q=j+\"/\"+\"model\"\n",
    "    path=p+q\n",
    "    if not os.path.exists(path):\n",
    "      os.makedirs(path)\n",
    "    else:\n",
    "      shutil.rmtree(path)           \n",
    "      os.makedirs(path)\n",
    "    #try:\n",
    "      #os.makedirs(path)\n",
    "    #except OSError:\n",
    "      #print (\"Creation of the directory %s failed\" % path)\n",
    "    #else:\n",
    "      #print (\"Successfully created the directory %s\" % path)\n",
    "  data1=dataimpute(data1)\n",
    "  data2=dataimpute(data2)\n",
    "  data3=dataimpute(data3)\n",
    "  end = datetime.date.today()-datetime.timedelta(days=2)\n",
    "  y1 = data1[['Adj Close']]\n",
    "  X1 = data1[['Volume']]\n",
    "  X1_data=X1.loc['2017-01-01':'2019-12-31',:]\n",
    "  X1_test=X1.loc['2020-01-01':end,:]\n",
    "  y1_data=y1.loc['2017-01-01':'2019-12-31',:]\n",
    "  y1_test=y1.loc['2020-01-01':end,:]\n",
    "  X1_norm=datapreprocess(X1_data)\n",
    "  X1_test=datapreprocess(X1_test)\n",
    "  X1_train, X1_val, y1_train, y1_val=train_test_split(X1_norm,y1_data,test_size=0.3,random_state=0)\n",
    "  \n",
    "  y2 = data2[['Adj Close']]\n",
    "  X2 = data2[['Volume']]\n",
    "  X2_data=X2.loc['2017-01-01':'2019-12-31',:]\n",
    "  X2_test=X2.loc['2020-01-01':end,:]\n",
    "  y2_data=y2.loc['2017-01-01':'2019-12-31',:]\n",
    "  y2_test=y2.loc['2020-01-01':end,:]\n",
    "  X2_norm=datapreprocess(X2_data)\n",
    "  X2_train, X2_val, y2_train, y2_val=train_test_split(X2_data,y2_data,test_size=0.3,random_state=0)\n",
    "  \n",
    "  y3 = data3[['Adj Close']]\n",
    "  X3 = data3[['Volume']]\n",
    "  X3_data=X3.loc['2017-01-01':'2019-12-31',:]\n",
    "  X3_test=X3.loc['2020-01-01':end,:]\n",
    "  y3_data=y3.loc['2017-01-01':'2019-12-31',:]\n",
    "  y3_test=y3.loc['2020-01-01':end,:]\n",
    "  X3_norm=datapreprocess(X3_data)\n",
    "  X3_train, X3_val, y3_train, y3_val=train_test_split(X3_data,y3_data,test_size=0.3,random_state=0)\n",
    "  return X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,X3_train,X3_val,X3_test,y3_train,y3_val,y3_test,y1_data,y2_data,y3_data,X1,X2,X3,y1,y2,y3,one,two,three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zBWxJsgVMEDx"
   },
   "outputs": [],
   "source": [
    "def plotdiff(test_data,predictions,dir,model):\n",
    "  plt.plot(test_data.index, predictions, color='blue', linestyle='dashed',label='Predicted Price')\n",
    "  plt.plot(test_data.index, test_data, color='red', label='Actual Adjusted Close Price')\n",
    "  plt.title('Adjusted Close Price Prediction')\n",
    "  plt.xlabel('Dates')\n",
    "  plt.ylabel('Adjusted Close Prices')\n",
    "  plt.legend()\n",
    "  plt.savefig(dir + \"/model\"+\"/\"+ model +\".png\")\n",
    "  plt.clf()\n",
    "  return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FLh7L-HG-QKQ"
   },
   "source": [
    "# LINEAR REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mgtu_UCkxZ_a"
   },
   "source": [
    "Linear regression quantifies the relationship between one or more predictor variable and one outcome variable. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "bFM9fXN29giQ"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oF3wiYOzuUx6"
   },
   "outputs": [],
   "source": [
    "def linear(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir):\n",
    "  linear=LinearRegression()\n",
    "  linear.fit(X1_train,y1_train)\n",
    "  y1_pred1=linear.predict(X1_val)\n",
    "  y1_pred=pd.DataFrame(linear.predict(X1_test))\n",
    "  mse=metrics.mean_squared_error(y1_val,y1_pred1)\n",
    "  rmse1=np.sqrt(mse)\n",
    "  model=\"LINEAR REGRESSION\"\n",
    "  plotdiff(y1_test,y1_pred,dir,model)\n",
    "  return y1_pred,rmse1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-WvyuJCPrE5"
   },
   "source": [
    "# LASSO REGRESSION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qEnGEvg3yUSw"
   },
   "source": [
    "Lasso regression is a type of linear regression that uses shrinkage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "F1a3YHG-_Pgd"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yRRUY4FwGNf0"
   },
   "outputs": [],
   "source": [
    "def lasso(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir):\n",
    "  lasso=Lasso()\n",
    "  lasso.fit(X1_train,y1_train)\n",
    "  y1_pred1=lasso.predict(X1_val)\n",
    "  y1_pred=pd.DataFrame(lasso.predict(X1_test))\n",
    "  mse=metrics.mean_squared_error(y1_val,y1_pred1)\n",
    "  rmse3=np.sqrt(mse)\n",
    "  model=\"LASSO REGRESSION\"\n",
    "  plotdiff(y1_test,y1_pred,dir,model)\n",
    "  return y1_pred,rmse3\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MjoFx9VuPvx3"
   },
   "source": [
    "# ELASTIC NET REGRESSION\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JPFUay0-0W_y"
   },
   "source": [
    "The Elastic Net is a regularized regression method that linearly combines the L1 and L2 penalties of the lasso and ridge methods. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "igsgf-9I_kj1"
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DdR2S9-GHZNm"
   },
   "outputs": [],
   "source": [
    "def EN(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir):\n",
    "  EN=ElasticNet()\n",
    "  EN.fit(X1_train,y1_train)\n",
    "  y1_pred1=EN.predict(X1_val)\n",
    "  y1_pred=pd.DataFrame(EN.predict(X1_test))\n",
    "  mse=metrics.mean_squared_error(y1_val,y1_pred1)\n",
    "  rmse4=np.sqrt(mse)\n",
    "  model=\"ELASTIC NET REGRESSION\"\n",
    "  plotdiff(y1_test,y1_pred,dir,model)\n",
    "  return y1_pred,rmse4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Tcg0eA1X_8ed"
   },
   "source": [
    "# DECISION TREE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "6YzNZZyB0jnn"
   },
   "source": [
    "![alt text](https://res.cloudinary.com/practicaldev/image/fetch/s--NOtmmf5a--/c_limit%2Cf_auto%2Cfl_progressive%2Cq_66%2Cw_880/https://twilio-cms-prod.s3.amazonaws.com/original_images/tree.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xKgATXYz0-s_"
   },
   "source": [
    "Decision tree builds regression  models in the form of a tree structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Yn0JRUnAAhw"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "txssZ_kpH4-w"
   },
   "outputs": [],
   "source": [
    "def DT(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir):\n",
    "  DT=DecisionTreeRegressor()\n",
    "  DT.fit(X1_train,y1_train)\n",
    "  y1_pred1=DT.predict(X1_val)\n",
    "  y1_pred=pd.DataFrame(DT.predict(X1_test))\n",
    "  mse=metrics.mean_squared_error(y1_val,y1_pred1)\n",
    "  rmse5=np.sqrt(mse)\n",
    "  model=\"DECISION TREE\"\n",
    "  plotdiff(y1_test,y1_pred,dir,model)\n",
    "  return y1_pred,rmse5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MYQRIyd1P58b"
   },
   "source": [
    "# KNN MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VbXj186e1S09"
   },
   "source": [
    "![alt text](https://miro.medium.com/max/1280/1*b9BXv0uAkbSAn8MJIa4-_Q.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZDVSjxIY1K1R"
   },
   "source": [
    "K nearest neighbors is a simple algorithm that stores all available cases and predict the numerical target based on a similarity measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kBqReRQcJPXq"
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7vEFri-3ALuX"
   },
   "outputs": [],
   "source": [
    "def KNN(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir):\n",
    "  KNN=KNeighborsRegressor()\n",
    "  KNN.fit(X1_train,y1_train)\n",
    "  y1_pred1=KNN.predict(X1_val)\n",
    "  y1_pred=pd.DataFrame(KNN.predict(X1_test))\n",
    "  mse=metrics.mean_squared_error(y1_val,y1_pred1)\n",
    "  rmse6=np.sqrt(mse)\n",
    "  model=\"KNN MODEL\"\n",
    "  plotdiff(y1_test,y1_pred,dir,model)\n",
    "  return y1_pred,rmse6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Od4trFZlP8xV"
   },
   "source": [
    "# SVR MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mrG4LWu812tF"
   },
   "source": [
    "![alt text](https://www.semspirit.com//wp-content/uploads/sites/17154/2017/10/PY-SVR-model-capture-800x450-compress-50.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Nj8ZdN1A4bti"
   },
   "source": [
    " Support Vector Regression (SVR) applies the idea of SVM to predict real values rather than a class.\n",
    "\n",
    "> SVR acknowledges the presence of non-linearity in the data and provides a proficient prediction model.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aDRCznTXJzgi"
   },
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RIih1dCWAfm-"
   },
   "outputs": [],
   "source": [
    "def svm(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir):\n",
    "  svr=SVR()\n",
    "  svr.fit(X1_train,y1_train)\n",
    "  y1_pred1=svr.predict(X1_val)\n",
    "  y1_pred=pd.DataFrame(svr.predict(X1_test))\n",
    "  mse=metrics.mean_squared_error(y1_val,y1_pred1)\n",
    "  rmse7=np.sqrt(mse)\n",
    "  model=\"SVR MODEL\"\n",
    "  plotdiff(y1_test,y1_pred,dir,model)\n",
    "  return y1_pred,rmse7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hPprzoFZKGRd"
   },
   "source": [
    "# SENTIMENT ANALYSIS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "06hh392B5pSr"
   },
   "source": [
    "![alt text](https://thumbs.gfycat.com/EnchantedYellowishBarasinga-small.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yEI1L8Sf5tRM"
   },
   "source": [
    "Neural networks are a set of algorithms, modeled loosely after the human brain, that are designed to recognize patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t5NbceKnWOJj"
   },
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B2S2OQFpKFwY"
   },
   "outputs": [],
   "source": [
    "def Sentiment(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,sentiment,dir):\n",
    "  X1_train.loc[:,'Sentiment']=sentiment\n",
    "  X1_val.loc[:,'Sentiment']=sentiment\n",
    "  X1_test.loc[:,'Sentiment']=sentiment\n",
    "  clf = MLPRegressor()\n",
    "  clf.fit(X1_train, y1_train)\n",
    "  y1_pred1=clf.predict(X1_val)\n",
    "  y1_pred=pd.DataFrame(clf.predict(X1_test))\n",
    "  mse=metrics.mean_squared_error(y1_val,y1_pred1)\n",
    "  rmse7=np.sqrt(mse)\n",
    "  model=\"SENTIMENT ANALYSIS\"\n",
    "  plotdiff(y1_test,y1_pred,dir,model)\n",
    "  return y1_pred,rmse7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ChIH7huIyREs"
   },
   "source": [
    "# ENSEMBLE MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "sWog1Y2XyHLo"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import ExtraTreesRegressor\n",
    "from sklearn.ensemble import AdaBoostRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ol_7NHF56_2t"
   },
   "source": [
    "![alt text](https://miro.medium.com/max/1280/1*9kACduxnce_JdTrftM_bsA.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jeYjtjNFxvf3"
   },
   "outputs": [],
   "source": [
    "def E1(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir):\n",
    "  clf = RandomForestRegressor()\n",
    "  clf.fit(X1_train, y1_train)\n",
    "  y1_pred1=clf.predict(X1_val)\n",
    "  y1_pred=pd.DataFrame(clf.predict(X1_test))\n",
    "  mse=metrics.mean_squared_error(y1_val,y1_pred1)\n",
    "  rmse7=np.sqrt(mse)\n",
    "  model=\"RANDOM FOREST REGRESSOR\"\n",
    "  plotdiff(y1_test,y1_pred,dir,model)\n",
    "  return y1_pred,rmse7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VjCqubKi7XbO"
   },
   "source": [
    "![alt text](https://miro.medium.com/max/900/1*IFoOIqlshjtQ34BpsLsIrg.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mCOin6Nyx4mG"
   },
   "outputs": [],
   "source": [
    "def E2(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir):\n",
    "  clf = GradientBoostingRegressor()\n",
    "  clf.fit(X1_train, y1_train)\n",
    "  y1_pred1=clf.predict(X1_val)\n",
    "  y1_pred=pd.DataFrame(clf.predict(X1_test))\n",
    "  mse=metrics.mean_squared_error(y1_val,y1_pred1)\n",
    "  rmse7=np.sqrt(mse)\n",
    "  model=\"GRADIENT BOOSTING REGRESSOR\"\n",
    "  plotdiff(y1_test,y1_pred,dir,model)\n",
    "  return y1_pred,rmse7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cVG1ifTzx5aK"
   },
   "outputs": [],
   "source": [
    "def E3(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir):\n",
    "  clf = AdaBoostRegressor()\n",
    "  clf.fit(X1_train, y1_train)\n",
    "  y1_pred1=clf.predict(X1_val)\n",
    "  y1_pred=pd.DataFrame(clf.predict(X1_test))\n",
    "  mse=metrics.mean_squared_error(y1_val,y1_pred1)\n",
    "  rmse7=np.sqrt(mse)\n",
    "  model=\"ADA BOOST REGRESSOR\"\n",
    "  plotdiff(y1_test,y1_pred,dir,model)\n",
    "  return y1_pred,rmse7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3oRL4n-v8bbO"
   },
   "source": [
    "![alt text](https://thumbs.gfycat.com/RigidFantasticBlackfly-size_restricted.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xub1qfwTx6Al"
   },
   "outputs": [],
   "source": [
    "def E4(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir):\n",
    "  clf = ExtraTreesRegressor()\n",
    "  clf.fit(X1_train, y1_train)\n",
    "  y1_pred1=clf.predict(X1_val)\n",
    "  y1_pred=pd.DataFrame(clf.predict(X1_test))\n",
    "  mse=metrics.mean_squared_error(y1_val,y1_pred1)\n",
    "  rmse7=np.sqrt(mse)\n",
    "  model=\"EXTRA TREES REGRESSOR\"\n",
    "  plotdiff(y1_test,y1_pred,dir,model)\n",
    "  return y1_pred,rmse7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "0QfSE9NoIYXR"
   },
   "source": [
    "# TIME SERIES MODELS "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-kIXV5KP-zk2"
   },
   "source": [
    "![alt text](https://i.pinimg.com/originals/57/2f/8c/572f8cbe4c9f69c217bdc33b82eb0c28.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iMjV06rwLjNS"
   },
   "source": [
    "# TIME SERIES PARTITION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5ewmIga27Jr-"
   },
   "source": [
    "**DATA WAS PARTITIONED AS TRAINING SET(2017-2019) AND TEST SET(2020)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uRJ1yyKXTWxJ"
   },
   "outputs": [],
   "source": [
    "from statsmodels.graphics.tsaplots import plot_acf  #autocorrelation\n",
    "from statsmodels.tsa.stattools import adfuller as ADF  # stable test\n",
    "from statsmodels.graphics.tsaplots import plot_pacf    #pacf\n",
    "from statsmodels.stats.diagnostic import acorr_ljungbox    #white noise\n",
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "88dP8BS0RUFF"
   },
   "outputs": [],
   "source": [
    "def testarima(d):\n",
    "  data1,data2,data3,one,two,three=dataextract(d)\n",
    "  data1=dataimpute(data1)\n",
    "  data2=dataimpute(data2)\n",
    "  data3=dataimpute(data3)\n",
    "  data1=data1.loc[:,'Adj Close']\n",
    "  data2=data2.loc[:,'Adj Close']\n",
    "  data3=data3.loc[:,'Adj Close']\n",
    "  train_data1, test_data1 =data1[0:int(len(data1)*0.7)], data1[int(len(data1)*0.7)-1:]\n",
    "  train_data2, test_data2 =data2[0:int(len(data2)*0.7)], data2[int(len(data2)*0.7)-1:]\n",
    "  train_data3, test_data3 =data3[0:int(len(data3)*0.7)], data3[int(len(data3)*0.7)-1:]\n",
    "  return train_data1,train_data2,train_data3,test_data1,test_data2,test_data3,one,two,three"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j-aKCsq6RcDC"
   },
   "outputs": [],
   "source": [
    "def plotarima(train_data,test_data,dir):\n",
    "  plt.figure(figsize=(12,7))\n",
    "  plt.title('Prices')\n",
    "  plt.xlabel('Dates')\n",
    "  plt.ylabel('Prices')\n",
    "  plt.plot(train_data,color='blue', label='Training Data')\n",
    "  plt.plot(test_data,color='green', label='Testing Data')\n",
    "  plt.legend()\n",
    "  plt.savefig(dir +\"/model\"+ \"/Time Series Partition graph.png\")\n",
    "  return plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VHwo9lpTLwe0"
   },
   "source": [
    "# STATIONARITY TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2DmGCWgF-m3S"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.stattools import adfuller"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CsiLXKtGLv8Q"
   },
   "outputs": [],
   "source": [
    "def test_stationarity(timeseries,dir):\n",
    "    \n",
    "    #Determing rolling statistics\n",
    "    rolmean = pd.Series(timeseries).rolling(window=12).mean()\n",
    "    rolstd = pd.Series(timeseries).rolling(window=12).std()\n",
    "\n",
    "    #Plot rolling statistics:\n",
    "    plt.style.use('seaborn')\n",
    "    rcParams['figure.figsize'] = 20,10\n",
    "    orig = plt.plot(timeseries,label='Original')\n",
    "    mean = plt.plot(rolmean, label='Rolling Mean')\n",
    "    std = plt.plot(rolstd, label = 'Rolling Std')\n",
    "    plt.legend(loc='best')\n",
    "    plt.title('Rolling Mean & Standard Deviation')\n",
    "    plt.show(block=False)\n",
    "    \n",
    "    #Perform Dickey-Fuller test:\n",
    "    print('Results of Dickey-Fuller Test:')\n",
    "    dftest = adfuller(timeseries, autolag='AIC')\n",
    "    dfoutput = pd.Series(dftest[0:4], index=['Test Statistic','p-value','#Lags Used','Number of Observations Used'])\n",
    "    for key,value in dftest[4].items():\n",
    "        dfoutput['Critical Value (%s)'%key] = value\n",
    "    temp1=pd.DataFrame(dfoutput)\n",
    "    temp1.to_csv(dir+\"/model\"+\"/Results of Dickey-Fuller Test.csv\")\n",
    "    return temp1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7fEboIgCegcK"
   },
   "source": [
    "# WHITE NOISE TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "wz3QuZK3eiLs"
   },
   "outputs": [],
   "source": [
    "def whitenoisetest(train1,dir):\n",
    "  temp2=acorr_ljungbox(train1,lags=1)\n",
    "  temp2=pd.DataFrame(temp2)\n",
    "  temp2.to_csv(dir+\"/model\"+\"/Results of White  Test <0.05 stable and not white noise.csv\")\n",
    "  return temp2\n",
    "  \n",
    "#<0.05 stable and not white noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "psWmjsme8iCR"
   },
   "source": [
    "# ACF and PACF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TG8NiBIM8ese"
   },
   "outputs": [],
   "source": [
    "def ACF(train_data,dir):\n",
    "  D_df = train_data.diff(periods=1).dropna()\n",
    "  D_df.columns = ['df1 diff']\n",
    "  ADF_df_p=ADF(D_df)\n",
    "  plot_pacf(D_df)\n",
    "  plt.savefig(dir +\"/model\"+ \"/pacf graph.png\")\n",
    "  plt.clf()\n",
    "  plot_acf(D_df)\n",
    "  plt.savefig(dir +\"/model\"+ \"/acf graph.png\")\n",
    "  plt.clf()\n",
    "  title=\"p-value of original sequence adf test is \" +str(ADF_df_p)\n",
    "  return title\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zuVe55GGa8S6"
   },
   "source": [
    "# MA MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7Hum7lTG-6Cm"
   },
   "source": [
    "![alt text](https://miro.medium.com/max/1200/1*8GeFfU9itlpiz_DjQzX3uw.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TCLzOEV5MJxu"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from math import sqrt\n",
    "!pip install pyramid-arima\n",
    "from pyramid.arima import auto_arima\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pLJhJqCTdgCv"
   },
   "outputs": [],
   "source": [
    "def ma(train,test,dir):\n",
    "  preds = []\n",
    "  for i in range(0,test.shape[0]):\n",
    "    x = train[len(train)-test.shape[0]+i:].sum() + sum(preds)\n",
    "    y = x/test.shape[0]\n",
    "    preds.append(y)\n",
    "  # checking the results (RMSE value)\n",
    "  rmse=sqrt(mean_squared_error(test,preds))\n",
    "  plt.plot(train,color='green', label='Training Data')\n",
    "  plt.plot(test.index, preds, marker='o', linestyle='dashed', \n",
    "          label='Predicted Price')\n",
    "  plt.plot(test.index, test, color='red', label='Actual Price')\n",
    "  plt.title('Price Prediction')\n",
    "  plt.xlabel('Dates')\n",
    "  plt.ylabel('Prices')\n",
    "  plt.legend()\n",
    "  plt.savefig(dir +\"/model\"+ \"/MA MODEL.png\")\n",
    "  plt.clf\n",
    "  preds=pd.DataFrame(preds)\n",
    "  return preds,rmse\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ECBI9RKwnrmt"
   },
   "source": [
    "# ARIMA MODEL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "2MVcKCzy_om3"
   },
   "source": [
    "![alt text](https://miro.medium.com/max/1260/1*GFGJDj5ULD1JgHiq6CvH6A.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_06bgOVDfA7L"
   },
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima_model import ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WZErAGpmdVpz"
   },
   "outputs": [],
   "source": [
    "def armodel(train_data,test_data,dir):\n",
    "  try:\n",
    "    aa=auto_arima(train_data, start_p=1, start_q=1, max_p=3, max_q=3,m=12,start_P=1,start_Q=1,seasonal=True,d=1, D=1, trace=True,error_action='ignore',  suppress_warnings=True, stepwise=True)\n",
    "    train_ar = train_data.values\n",
    "    test_ar = test_data.values\n",
    "    history = [x for x in train_ar]\n",
    "    print(history)\n",
    "    predictions = list()\n",
    "    for t in range(len(test_ar)):\n",
    "      model = ARIMA(history,order=(aa.order))\n",
    "      model_fit = model.fit()\n",
    "      output = model_fit.forecast()\n",
    "      yhat = output[0]\n",
    "      predictions.append(yhat)\n",
    "      obs = test_ar[t]\n",
    "      history.append(obs)\n",
    "    error = mean_squared_error(test_ar, predictions)\n",
    "    rmse=sqrt(error)\n",
    "    plt.plot(train_data,color='green', label='Training Data')\n",
    "    plt.plot(test_data.index, predictions, marker='o', linestyle='dashed', \n",
    "    label='Predicted Price')\n",
    "    plt.plot(test_data.index, test_data, color='red', label='Actual Price')\n",
    "    plt.title('Price Prediction')\n",
    "    plt.xlabel('Dates')\n",
    "    plt.ylabel('Prices')\n",
    "    plt.legend()\n",
    "    plt.savefig(dir +\"/model\"+ \"/ARIMA MODEL.png\")\n",
    "    plt.clf\n",
    "  except ValueError:\n",
    "     a = np.zeros(shape=(len(test_data),1)) #Bad performing model\n",
    "     predictions=pd.DataFrame(a)\n",
    "     #d1=[test_data.mean()]*(len(test_data)) #Better bad performing model but we don't want it to be best\n",
    "     #predictions=pd.DataFrame(d1)\n",
    "     error = mean_squared_error(test_ar, predictions)\n",
    "     rmse=sqrt(error)\n",
    "     return predictions,rmse \n",
    "  else:\n",
    "     predictions=pd.DataFrame(predictions)\n",
    "     return predictions,rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Vrd1fCiDBvyc"
   },
   "source": [
    "# COMPARING MODELS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NolkFL4uAoa8"
   },
   "source": [
    "![alt text](https://media3.giphy.com/media/sRFEa8lbeC7zbcIZZR/giphy.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pvIi3EUl_vqp"
   },
   "source": [
    "**WE CHOSE THE BEST MODEL THAT FITS BY TAKING THE LOWEST RMSE VALUE.**\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j9ogYdSZmP_Y"
   },
   "outputs": [],
   "source": [
    "def models1(d):\n",
    "  X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,X3_train,X3_val,X3_test,y3_train,y3_val,y3_test,y1_data,y2_data,y3_data,X1,X2,X3,y1,y2,y3,one,two,three=datapartition(d)\n",
    "  \n",
    "  dir=directory(d)\n",
    "  dir1=dir+\"/\"+one\n",
    "  y_pred11,rmse11=linear(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir1)\n",
    "  y_pred13,rmse13=lasso(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir1)\n",
    "  y_pred14,rmse14=EN(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir1)\n",
    "  y_pred15,rmse15=DT(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir1)\n",
    "  y_pred16,rmse16=KNN(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir1)\n",
    "  y_pred17,rmse17=svm(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir1)\n",
    "  y_pred18,rmse18=Sentiment(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,10,dir1)\n",
    "  y_pred19,rmse19=E1(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir1)\n",
    "  y_pred110,rmse110=E2(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir1)\n",
    "  y_pred111,rmse111=E3(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir1)\n",
    "  y_pred112,rmse112=E4(X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,dir1)\n",
    "  \n",
    "  dir2=dir+\"/\"+two\n",
    "  y_pred21,rmse21=linear(X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,dir2)\n",
    "  y_pred23,rmse23=lasso(X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,dir2)\n",
    "  y_pred24,rmse24=EN(X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,dir2)\n",
    "  y_pred25,rmse25=DT(X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,dir2)\n",
    "  y_pred26,rmse26=KNN(X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,dir2)\n",
    "  y_pred27,rmse27=svm(X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,dir2)\n",
    "  y_pred28,rmse28=Sentiment(X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,9,dir2)\n",
    "  y_pred29,rmse29=E1(X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,dir2)\n",
    "  y_pred210,rmse210=E2(X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,dir2)\n",
    "  y_pred211,rmse211=E3(X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,dir2)\n",
    "  y_pred212,rmse212=E4(X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,dir2)\n",
    "  \n",
    "  dir3=dir+\"/\"+three\n",
    "  y_pred31,rmse31=linear(X3_train,X3_val,X3_test,y3_train,y3_val,y3_test,dir3)\n",
    "  y_pred33,rmse33=lasso(X3_train,X3_val,X3_test,y3_train,y3_val,y3_test,dir3)\n",
    "  y_pred34,rmse34=EN(X3_train,X3_val,X3_test,y3_train,y3_val,y3_test,dir3)\n",
    "  y_pred35,rmse35=DT(X3_train,X3_val,X3_test,y3_train,y3_val,y3_test,dir3)\n",
    "  y_pred36,rmse36=KNN(X3_train,X3_val,X3_test,y3_train,y3_val,y3_test,dir3)\n",
    "  y_pred37,rmse37=svm(X3_train,X3_val,X3_test,y3_train,y3_val,y3_test,dir3)\n",
    "  y_pred38,rmse38=Sentiment(X3_train,X3_val,X3_test,y3_train,y3_val,y3_test,8,dir3)\n",
    "  y_pred39,rmse39=E1(X3_train,X3_val,X3_test,y3_train,y3_val,y3_test,dir3)\n",
    "  y_pred310,rmse310=E2(X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,dir2)\n",
    "  y_pred311,rmse311=E3(X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,dir2)\n",
    "  y_pred312,rmse312=E4(X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,dir2)\n",
    "\n",
    "  return  y_pred11,rmse11,y_pred13,rmse13,y_pred14,rmse14,y_pred15,rmse15,y_pred16,rmse16,y_pred17,rmse17,y_pred18,rmse18,y_pred19,rmse19,y_pred110,rmse110,y_pred111,rmse111,y_pred112,rmse112,y_pred21,rmse21,y_pred23,rmse23,y_pred24,rmse24,y_pred25,rmse25,y_pred26,rmse26,y_pred27,rmse27,y_pred28,rmse28,y_pred29,rmse29,y_pred210,rmse210,y_pred211,rmse211,y_pred212,rmse212,y_pred31,rmse31,y_pred33,rmse33,y_pred34,rmse34,y_pred35,rmse35,y_pred36,rmse36,y_pred37,rmse37,y_pred38,rmse38,y_pred39,rmse39,y_pred310,rmse310,y_pred311,rmse311,y_pred312,rmse312\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YZPjnSKBSM1-"
   },
   "outputs": [],
   "source": [
    "def models2(d):\n",
    "  train1,train2,train3,test1,test2,test3,one,two,three=testarima(d)\n",
    "  dir=directory(d)\n",
    "  dir1=dir+\"/\"+one\n",
    "  plotarima(train1,test1,dir1)\n",
    "  t1=test_stationarity(train1,dir1) \n",
    "  w1=whitenoisetest(train1,dir1)\n",
    "  title1=ACF(train1,dir1)\n",
    "  print(title1)\n",
    "  pred11,rm11=armodel(train1,test1,dir1)\n",
    "  pred12,rm12=ma(train1,test1,dir1)\n",
    "\n",
    "  dir2=dir+\"/\"+two\n",
    "  plotarima(train2,test2,dir2)\n",
    "  t2=test_stationarity(train2,dir2)\n",
    "  w2=whitenoisetest(train2,dir2)\n",
    "  title2=ACF(train2,dir2)\n",
    "  print(title2)\n",
    "  pred21,rm21=armodel(train2,test2,dir2)\n",
    "  pred22,rm22=ma(train2,test2,dir2)\n",
    "  \n",
    "  dir3=dir+\"/\"+three\n",
    "  plotarima(train3,test3,dir3)\n",
    "  t3=test_stationarity(train3,dir3)\n",
    "  w3=whitenoisetest(train3,dir3)\n",
    "  title3=ACF(train3,dir3)\n",
    "  print(title3)\n",
    "  pred31,rm31=armodel(train3,test3,dir3)\n",
    "  pred32,rm32=ma(train3,test3,dir3)\n",
    "  return pred11,rm11,pred12,rm12,pred21,rm21,pred22,rm22,pred31,rm31,pred32,rm32\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZGZv8aNdzgxQ"
   },
   "source": [
    "# Residuals Comparision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MGjRQPuXA1jY"
   },
   "source": [
    " **WE ALSO CHECKED THE SPREAD OF RESIDUALS OF MODELS BY BOXPLOTS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4hw3pdKFDszx"
   },
   "outputs": [],
   "source": [
    "def box(y1_test,y_pred11,y_pred13,y_pred14,y_pred15,y_pred16,y_pred17,y_pred18,y_pred19,y_pred110,y_pred111,y_pred112,pred11,pred12,dir1):\n",
    "  y1_test=y1_test.reset_index()\n",
    "  linear=np.subtract(y1_test.loc[:,'Adj Close'],y_pred11.loc[:,0])\n",
    "  lasso=np.subtract(y1_test.loc[:,'Adj Close'],y_pred13.loc[:,0])\n",
    "  en=np.subtract(y1_test.loc[:,'Adj Close'],y_pred14.loc[:,0])\n",
    "  dt=np.subtract(y1_test.loc[:,'Adj Close'],y_pred15.loc[:,0])\n",
    "  knn=np.subtract(y1_test.loc[:,'Adj Close'],y_pred16.loc[:,0])\n",
    "  svr=np.subtract(y1_test.loc[:,'Adj Close'],y_pred17.loc[:,0])\n",
    "  nn=np.subtract(y1_test.loc[:,'Adj Close'],y_pred18.loc[:,0])\n",
    "  e1=np.subtract(y1_test.loc[:,'Adj Close'],y_pred19.loc[:,0])\n",
    "  e2=np.subtract(y1_test.loc[:,'Adj Close'],y_pred110.loc[:,0])\n",
    "  e3=np.subtract(y1_test.loc[:,'Adj Close'],y_pred111.loc[:,0])\n",
    "  e4=np.subtract(y1_test.loc[:,'Adj Close'],y_pred112.loc[:,0])\n",
    "  ar=np.subtract(y1_test.loc[:,'Adj Close'],pred11.loc[:,0])\n",
    "  ma=np.subtract(y1_test.loc[:,'Adj Close'],pred12.loc[:,0])\n",
    "\n",
    "  ar=ar[np.logical_not(np.isnan(ar))] \n",
    "  ma=ma[np.logical_not(np.isnan(ma))]\n",
    "\n",
    "  residuals=pd.DataFrame()\n",
    "  residuals=pd.concat([linear,lasso,en,dt,knn,svr,nn,e1,e2,e3,e4,ar,ma],axis=1)\n",
    "  residuals.columns=['LINEAR REGRESSION','LASSO REGRESSION','ELASTIC NET REGRESSION','DECISION TREE','KNN MODEL','SVR MODEL','SENTIMENT ANALYSIS','RANDOM FOREST REGRESSOR','GRADIENT BOOST REGRESSOR','ADA BOOST REGRESSOR','EXTRA TREES REGRESSOR','ARIMA MODEL','MA MODEL']\n",
    "\n",
    "  data=[linear,lasso,en,dt,knn,svr,nn,e1,e2,e3,e4,ar,ma]  \n",
    "  #building figure\n",
    "  fig = plt.figure()\n",
    "  fig.suptitle('Residuals Comparison')\n",
    "  ax = fig.add_subplot(111)\n",
    "  plt.boxplot(data)\n",
    "  ax.set_xticklabels(residuals.columns)\n",
    "  plt.xticks(rotation='vertical')\n",
    "\n",
    "  plt.savefig(dir1 + \"/model\"+\"/Residuals Comparision\"+\".png\")\n",
    "  return plt.clf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "k26dQCAqWN0y"
   },
   "outputs": [],
   "source": [
    "def compare(rmse1,rmse2,rmse3,rmse4,rmse5,rmse6,rmse7,rmse8,rmse9,rmse10,rmse11,rmse12,rmse13):\n",
    "  rmse=pd.DataFrame()\n",
    "  rmse['Model']=['LINEAR REGRESSION','LASSO REGRESSION','ELASTIC NET REGRESSION','DECISION TREE','KNN MODEL','SVR MODEL','SENTIMENT ANALYSIS','RANDOM FOREST REGRESSOR','GRADIENT BOOST REGRESSOR','ADA BOOST REGRESSOR','EXTRA TREES REGRESSOR','ARIMA MODEL','MA MODEL']\n",
    "  rmse['RMSE']=[rmse1,rmse2,rmse3,rmse4,rmse5,rmse6,rmse7,rmse8,rmse9,rmse10,rmse11,rmse12,rmse13]\n",
    "  l=np.min(rmse[\"RMSE\"])\n",
    "  for i in range(len(rmse)):\n",
    "      if l==rmse.iloc[i]['RMSE']:\n",
    "        best=rmse.iloc[i][\"Model\"]\n",
    "  return l,best\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "eZg3gt3qozTD"
   },
   "outputs": [],
   "source": [
    "def finalmodel(d):\n",
    "  X1_train,X1_val,X1_test,y1_train,y1_val,y1_test,X2_train,X2_val,X2_test,y2_train,y2_val,y2_test,X3_train,X3_val,X3_test,y3_train,y3_val,y3_test,y1_data,y2_data,y3_data,X1,X2,X3,y1,y2,y3,one,two,three=datapartition(d)\n",
    "  y_pred11,rmse11,y_pred13,rmse13,y_pred14,rmse14,y_pred15,rmse15,y_pred16,rmse16,y_pred17,rmse17,y_pred18,rmse18,y_pred19,rmse19,y_pred110,rmse110,y_pred111,rmse111,y_pred112,rmse112,y_pred21,rmse21,y_pred23,rmse23,y_pred24,rmse24,y_pred25,rmse25,y_pred26,rmse26,y_pred27,rmse27,y_pred28,rmse28,y_pred29,rmse29,y_pred210,rmse210,y_pred211,rmse211,y_pred212,rmse212,y_pred31,rmse31,y_pred33,rmse33,y_pred34,rmse34,y_pred35,rmse35,y_pred36,rmse36,y_pred37,rmse37,y_pred38,rmse38,y_pred39,rmse39,y_pred310,rmse310,y_pred311,rmse311,y_pred312,rmse312=models1(d)\n",
    "\n",
    "  train_data1,train_data2,train_data3,test_data1,test_data2,test_data3,one,two,three=testarima(d)\n",
    "  pred11,rm11,pred12,rm12,pred21,rm21,pred22,rm22,pred31,rm31,pred32,rm32=models2(d)\n",
    "\n",
    "  dir=directory(d) \n",
    "\n",
    "  dir1=dir+\"/\"+one\n",
    "  l,best=compare(rmse11,rmse13,rmse14,rmse15,rmse16,rmse17,rmse18,rmse19,rmse110,rmse111,rmse112,rm11,rm12)\n",
    "  box(y1_test,y_pred11,y_pred13,y_pred14,y_pred15,y_pred16,y_pred17,y_pred18,y_pred19,y_pred110,y_pred111,y_pred112,pred11,pred12,dir1)\n",
    "  model=\"Best model is \"+best\n",
    "  \n",
    "  if l==rmse11:\n",
    "    plotdiff(y1_test,y_pred11,dir1,model)\n",
    "  elif l==rmse13:\n",
    "    plotdiff(y1_test,y_pred13,dir1,model)\n",
    "  elif l==rmse14:\n",
    "    plotdiff(y1_test,y_pred14,dir1,model)\n",
    "  elif l==rmse15:\n",
    "    plotdiff(y1_test,y_pred15,dir1,model)\n",
    "  elif l==rmse16:\n",
    "    plotdiff(y1_test,y_pred16,dir1,model)\n",
    "  elif l==rmse17:\n",
    "    plotdiff(y1_test,y_pred17,dir1,model)\n",
    "  elif l==rmse18:\n",
    "    plotdiff(y1_test,y_pred18,dir1,model)\n",
    "  elif l==rmse19:\n",
    "    plotdiff(y1_test,y_pred19,dir1,model)\n",
    "  elif l==rmse110:\n",
    "    plotdiff(y1_test,y_pred110,dir1,model)\n",
    "  elif l==rmse111:\n",
    "    plotdiff(y1_test,y_pred111,dir1,model)\n",
    "  elif l==rmse112:\n",
    "    plotdiff(y1_test,y_pred112,dir1,model)\n",
    "  elif l==rm11:\n",
    "    plotdiff(test_data1,pred11,dir1,model)\n",
    "  elif l==rm12:\n",
    "    plotdiff(test_data1,pred12,dir1,model)\n",
    "  else:\n",
    "    print(\"Error\")\n",
    "  \n",
    "  dir2=dir+\"/\"+two\n",
    "  l,best=compare(rmse21,rmse23,rmse24,rmse25,rmse26,rmse27,rmse28,rmse29,rmse210,rmse211,rmse212,rm21,rm22)\n",
    "  box(y2_test,y_pred21,y_pred23,y_pred24,y_pred25,y_pred26,y_pred27,y_pred28,y_pred29,y_pred210,y_pred211,y_pred212,pred21,pred22,dir2)\n",
    "  model=\"Best model is \"+best\n",
    "  \n",
    "  if l==rmse21:\n",
    "    plotdiff(y2_test,y_pred21,dir2,model)\n",
    "  elif l==rmse23:\n",
    "    plotdiff(y2_test,y_pred23,dir2,model)\n",
    "  elif l==rmse24:\n",
    "    plotdiff(y2_test,y_pred24,dir2,model)\n",
    "  elif l==rmse25:\n",
    "    plotdiff(y2_test,y_pred25,dir2,model)\n",
    "  elif l==rmse26:\n",
    "    plotdiff(y2_test,y_pred26,dir2,model)\n",
    "  elif l==rmse27:\n",
    "    plotdiff(y2_test,y_pred27,dir2,model)\n",
    "  elif l==rmse28:\n",
    "    plotdiff(y2_test,y_pred28,dir2,model)\n",
    "  elif l==rmse29:\n",
    "    plotdiff(y2_test,y_pred29,dir2,model)\n",
    "  elif l==rmse210:\n",
    "    plotdiff(y2_test,y_pred210,dir2,model)\n",
    "  elif l==rmse211:\n",
    "    plotdiff(y2_test,y_pred211,dir2,model)\n",
    "  elif l==rmse212:\n",
    "    plotdiff(y2_test,y_pred212,dir2,model)\n",
    "  elif l==rm21:\n",
    "    plotdiff(test_data2,pred21,dir2,model)\n",
    "  elif l==rm22:\n",
    "    plotdiff(test_data2,pred22,dir2,model)\n",
    "  else:\n",
    "    print(\"Error\")\n",
    "  dir3=dir+\"/\"+three\n",
    "  l,best=compare(rmse31,rmse33,rmse34,rmse35,rmse36,rmse37,rmse38,rmse39,rmse310,rmse311,rmse312,rm31,rm32)\n",
    "  box(y3_test,y_pred31,y_pred33,y_pred34,y_pred35,y_pred36,y_pred37,y_pred38,y_pred39,y_pred310,y_pred311,y_pred312,pred31,pred32,dir3)\n",
    "  model=\"Best model is \"+best\n",
    "  \n",
    "  if l==rmse31:\n",
    "    plotdiff(y3_test,y_pred31,dir3,model)\n",
    "  elif l==rmse33:\n",
    "    plotdiff(y3_test,y_pred33,dir3,model)\n",
    "  elif l==rmse34:\n",
    "    plotdiff(y3_test,y_pred34,dir3,model)\n",
    "  elif l==rmse35:\n",
    "    plotdiff(y3_test,y_pred35,dir3,model)\n",
    "  elif l==rmse36:\n",
    "    plotdiff(y3_test,y_pred36,dir3,model)\n",
    "  elif l==rmse37:\n",
    "    plotdiff(y3_test,y_pred37,dir3,model)\n",
    "  elif l==rmse38:\n",
    "    plotdiff(y3_test,y_pred38,dir3,model)\n",
    "  elif l==rmse39:\n",
    "    plotdiff(y3_test,y_pred39,dir3,model)\n",
    "  elif l==rmse310:\n",
    "    plotdiff(y3_test,y_pred310,dir3,model)\n",
    "  elif l==rmse311:\n",
    "    plotdiff(y3_test,y_pred311,dir3,model)\n",
    "  elif l==rmse312:\n",
    "    plotdiff(y3_test,y_pred312,dir3,model)\n",
    "  elif l==rm31:\n",
    "    plotdiff(test_data3,pred31,dir3,model)\n",
    "  elif l==rm32:\n",
    "    plotdiff(test_data3,pred32,dir3,model)\n",
    "  else:\n",
    "    print(\"Error\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "KZGwduhoKBei"
   },
   "outputs": [],
   "source": [
    "#finalmodel(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MebyoCpSOL-w"
   },
   "outputs": [],
   "source": [
    "#finalmodel(cd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ikU1TXXDOPyW"
   },
   "outputs": [],
   "source": [
    "#finalmodel(hc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pTiH8-3rOR3P"
   },
   "outputs": [],
   "source": [
    "#finalmodel(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kHsLA0qVOT_T"
   },
   "outputs": [],
   "source": [
    "#finalmodel(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mIHevfYSOWMn"
   },
   "outputs": [],
   "source": [
    "#finalmodel(cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Z0DHGH_pR0y4"
   },
   "source": [
    "# ***PART-III***\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gCzUhtfNFoz8"
   },
   "source": [
    "# **RESULTS**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "aAUa2iu7Bph0"
   },
   "source": [
    "![alt text](https://thedarkside.frantzmiccoli.com/res/metatrader.gif)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dNVSGcRn_A37"
   },
   "outputs": [],
   "source": [
    "years=1           #enter number of years\n",
    "date='2020-01-01' #date \n",
    "pay=1000000       #payment=1 million dollars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "L98ciV41b1Pm"
   },
   "outputs": [],
   "source": [
    "%pip install numpy-financial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-V3qqO-lb4Y5"
   },
   "outputs": [],
   "source": [
    "import numpy_financial as npf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nB3Va5kOFoNz"
   },
   "outputs": [],
   "source": [
    "def zombie(df):\n",
    "  data=df['Adj Close']\n",
    "  returns=pd.DataFrame.pct_change(data)\n",
    "  for i in range(len(data)):\n",
    "    if returns[i]<-10000:\n",
    "      p=\"May be a Potential Zombie Company\"\n",
    "      for j in range(i,len(data),1):\n",
    "        if returns[j]<=returns[i]:\n",
    "          continue\n",
    "        else:\n",
    "          p=\"Not a Potential Zombie Company\"\n",
    "          break\n",
    "    else:\n",
    "      p=\"Not a Potential Zombie Company\"\n",
    "  return p  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LG5-e3MjRpDo"
   },
   "outputs": [],
   "source": [
    "def results(years,date,pay,d):\n",
    "  data1,data2,data3,one,two,three=dataextract(d)\n",
    "  dir=directory(d)\n",
    "  data1=dataimpute(data1)\n",
    "  data2=dataimpute(data2)\n",
    "  data3=dataimpute(data3)\n",
    "  dir1=os.path.join(dir, one)\n",
    "  dir2=os.path.join(dir, two)\n",
    "  dir3=os.path.join(dir, three)\n",
    "  p1=zombie(data1)\n",
    "  p2=zombie(data2)\n",
    "  p3=zombie(data3)\n",
    "  df1=data1['Adj Close']\n",
    "  df2=data2['Adj Close']\n",
    "  df3=data3['Adj Close']\n",
    "  pv1=npf.pv(nper=years,pmt=pay,rate=0.12,fv=df1.loc[date])\n",
    "  pv2=npf.pv(nper=years,pmt=pay,rate=0.12,fv=df2.loc[date])\n",
    "  pv3=npf.pv(nper=years,pmt=pay,rate=0.12,fv=df3.loc[date])\n",
    "  npv1=npf.npv(rate=0.12,values=df1)\n",
    "  npv2=npf.npv(rate=0.12,values=df2)\n",
    "  npv3=npf.npv(rate=0.12,values=df3)\n",
    "  df1=df1.to_numpy()\n",
    "  df2=df2.to_numpy()\n",
    "  df3=df3.to_numpy()\n",
    "  irr1=npf.irr(df1)\n",
    "  irr2=npf.irr(df2)\n",
    "  irr3=npf.irr(df3)\n",
    "  irr1=np.nan_to_num(0.12)\n",
    "  irr2=np.nan_to_num(0.12)\n",
    "  irr3=np.nan_to_num(0.12)\n",
    "  roi1=npv1/pay \n",
    "  roi2=npv2/pay\n",
    "  roi3=npv3/pay\n",
    "  p1=zombie(data1)\n",
    "  p2=zombie(data2)\n",
    "  p3=zombie(data3)\n",
    "  \n",
    "  elements=['Ticker Symbol','Whether Zombie or not:','Present Value after 1 year if invested $1M on 2020-01-01:','Net Present Value at 12% Discount Rate:','Internal Rate of Return:','Return of Investment:']\n",
    "  a1=[one,p1,pv1,npv1,irr1,roi1]\n",
    "  a2=[two,p2,pv2,npv2,irr2,roi2]\n",
    "  a3=[three,p3,pv3,npv3,irr3,roi3]\n",
    "  b1=data1.describe()\n",
    "  b2=data2.describe()\n",
    "  b3=data3.describe()\n",
    "\n",
    "  pf1=pd.DataFrame(elements,columns=['Info'])\n",
    "  pf1['Answer']=a1\n",
    "  pf1=pf1.append(b1)\n",
    "  pf1.to_excel(dir1+\"/\"+one+\" Financial Portfolio Report.xlsx\")\n",
    "  \n",
    "  pf2=pd.DataFrame(elements,columns=['Info'])\n",
    "  pf2['Answer']=a2\n",
    "  pf2=pf2.append(b2)\n",
    "  pf2.to_excel(dir2+\"/\"+two+\" Financial Portfolio Report.xlsx\")\n",
    "\n",
    "  pf3=pd.DataFrame(elements,columns=['Info'])\n",
    "  pf3['Answer']=a3\n",
    "  pf3=pf3.append(b3)\n",
    "  pf3.to_excel(dir3+\"/\"+three+\" Financial Portfolio Report.xlsx\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6Ib6-DXt8plR"
   },
   "outputs": [],
   "source": [
    "#results(years,date,pay,t)\n",
    "#results(years,date,pay,cd)\n",
    "#results(years,date,pay,hc)\n",
    "#results(years,date,pay,f)\n",
    "#results(years,date,pay,u)\n",
    "#results(years,date,pay,cs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gd_GxC35WZj_"
   },
   "source": [
    "                                   \n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_kLcXccP83oe"
   },
   "source": [
    "# Future Scope for this Project\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> Improve Space and Time Complexity of the Algorithm\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "> More Variables like Alternative Data,Company Account Details,Sentiment etc\n",
    "\n",
    "> Results for all Stocks Companies\n",
    "\n",
    "> Comparison of different company stock information\n",
    "\n",
    "> Giving more suggestions or results using financial information\n",
    "\n",
    "> More assured stock data from other API using API key\n",
    "\n",
    "> Making  a software or app using GUI\n",
    "\n",
    "> Making a package to generate results as report in GitHub\n",
    "\n",
    "> Tuning more timeseries models and other models\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9BSEvL9jBtWD"
   },
   "source": [
    "![alt text](https://mir-s3-cdn-cf.behance.net/project_modules/max_1200/0642e775239417.5e4ba3436decf.gif)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Final Code team-9.ipynb",
   "private_outputs": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
